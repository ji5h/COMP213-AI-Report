@article{intelligentNetwork:2008,
  author = {Tooru Yamaguchi, Kubota Naoyuki and Yasufumi Takama},
  title = {Introduction to intelligent network systems},
  year = {2008},
}

@inproceedings{sign:2019,
author = {Bragg, Danielle and Koller, Oscar and Bellard, Mary and Berke, Larwan and Boudreault, Patrick and Braffort, Annelies and Caselli, Naomi and Huenerfauth, Matt and Kacorri, Hernisa and Verhoef, Tessa and Vogler, Christian and Ringel Morris, Meredith},
title = {Sign Language Recognition, Generation, and Translation: An Interdisciplinary Perspective},
year = {2019},
isbn = {9781450366762},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3308561.3353774},
doi = {10.1145/3308561.3353774},
abstract = {Developing successful sign language recognition, generation, and translation systems requires expertise in a wide range of fields, including computer vision, computer graphics, natural language processing, human-computer interaction, linguistics, and Deaf culture. Despite the need for deep interdisciplinary knowledge, existing research occurs in separate disciplinary silos, and tackles separate portions of the sign language processing pipeline. This leads to three key questions: 1) What does an interdisciplinary view of the current landscape reveal? 2) What are the biggest challenges facing the field? and 3) What are the calls to action for people working in the field? To help answer these questions, we brought together a diverse group of experts for a two-day workshop. This paper presents the results of that interdisciplinary workshop, providing key background that is often overlooked by computer scientists, a review of the state-of-the-art, a set of pressing challenges, and a call to action for the research community.},
booktitle = {Proceedings of the 21st International ACM SIGACCESS Conference on Computers and Accessibility},
pages = {16–31},
numpages = {16},
keywords = {and generation, asl, recognition, sign language, translation},
location = {Pittsburgh, PA, USA},
series = {ASSETS '19}
}

@INPROCEEDINGS{gesture:communication:2020,
  author={Dou, Wen Bang and Chin, Wei Hong and Kubota, Naoyuki},
  booktitle={2020 Joint 11th International Conference on Soft Computing and Intelligent Systems and 21st International Symposium on Advanced Intelligent Systems (SCIS-ISIS)}, 
  title={Hand Gesture Communication using Deep Learning based on Relevance Theory}, 
  year={2020},
  volume={},
  number={},
  pages={1-5},
  keywords={Semantics;Feature extraction;Image segmentation;Robots;Deep learning;Neurons;Gesture recognition;hand gesture recognition;environmental information;Mask R-CNN;DM-ARM},
  doi={10.1109/SCISISIS50064.2020.9322784}}

@INPROCEEDINGS{SAM:2023,
  author={Özbek, Muhammed Murat and Tekgöz, Hilal},
  booktitle={2023 8th International Conference on Computer Science and Engineering (UBMK)}, 
  title={Image Retrieval with Segment Anything and CNN Techniques}, 
  year={2023},
  volume={},
  number={},
  pages={131-136},
  keywords={Deep learning;Computer science;Image segmentation;Databases;Atmospheric modeling;Computational modeling;Image retrieval;segment anything;image retrieval;image simi-larity;segmentation;resnet-50},
  doi={10.1109/UBMK59864.2023.10286583}}

@InProceedings{10.1007/978-3-319-10590-1_53,
author="Zeiler, Matthew D.
and Fergus, Rob",
editor="Fleet, David
and Pajdla, Tomas
and Schiele, Bernt
and Tuytelaars, Tinne",
title="Visualizing and Understanding Convolutional Networks",
booktitle="Computer Vision -- ECCV 2014",
year="2014",
publisher="Springer International Publishing",
address="Cham",
pages="818--833",
abstract="Large Convolutional Network models have recently demonstrated impressive classification performance on the ImageNet benchmark Krizhevsky et al. [18]. However there is no clear understanding of why they perform so well, or how they might be improved. In this paper we explore both issues. We introduce a novel visualization technique that gives insight into the function of intermediate feature layers and the operation of the classifier. Used in a diagnostic role, these visualizations allow us to find model architectures that outperform Krizhevsky et al on the ImageNet classification benchmark. We also perform an ablation study to discover the performance contribution from different model layers. We show our ImageNet model generalizes well to other datasets: when the softmax classifier is retrained, it convincingly beats the current state-of-the-art results on Caltech-101 and Caltech-256 datasets.",
isbn="978-3-319-10590-1"
}

@INPROCEEDINGS{hand:gesture:yolo:2023,
  author={Herbaz, Nourdine and El Idrissi, Hassan and Badri, Abdelmajid},
  booktitle={2023 14th International Conference on Intelligent Systems: Theories and Applications (SITA)}, 
  title={Deep Learning Empowered Hand Gesture Recognition: using YOLO Techniques}, 
  year={2023},
  volume={},
  number={},
  pages={1-7},
  keywords={YOLO;Training;Human computer interaction;Deep learning;Adaptation models;Gesture recognition;Real-time systems;YOLO’s;Sign language;Hand Gesture Recognition;CNN;Deep Learning},
  doi={10.1109/SITA60746.2023.10373734}}


@INPROCEEDINGS{indonesian:sign:2020,
  author={Kembuan, Olivia and Caren Rorimpandey, Gladly and Milian Tompunu Tengker, Soenandar},
  booktitle={2020 2nd International Conference on Cybernetics and Intelligent System (ICORIS)}, 
  title={Convolutional Neural Network (CNN) for Image Classification of Indonesia Sign Language Using Tensorflow}, 
  year={2020},
  volume={},
  number={},
  pages={1-5},
  keywords={Assistive technology;Gesture recognition;Training;Internet;Convolutional neural networks;Image recognition;Image classification;Convolutional Neural Networks;Indonesian Sign Language;Tensorflow;Google Colaboratory;Image Classification},
  doi={10.1109/ICORIS50180.2020.9320810}}

@article{RCNN:2023,
    author = {Pulkit Sharma},
    title = {A Practical Implementation of the Faster R-CNN Algorithm for Object Detection (Part 2 – with Python codes)},
    journal = {Analytics Vidhya},
    year = {2023},
    url = {https://www.analyticsvidhya.com/blog/2018/11/implementation-faster-r-cnn-python-object-detection/},
}

@INPROCEEDINGS{segmentationRCNN:2018,
  author={Nguyen, Dinh-Ha and Le, Trung-Hieu and Tran, Thanh-Hai and Vu, Hai and Le, Thi-Lan and Doan, Huong-Giang},
  booktitle={2018 5th Asian Conference on Defense Technology (ACDT)}, 
  title={Hand segmentation under different viewpoints by combination of Mask R-CNN with tracking}, 
  year={2018},
  volume={},
  number={},
  pages={14-20},
  keywords={Image segmentation;Tracking;Feature extraction;Image resolution;Skin;Detectors;Neural networks;hand segmentation;neural network;deep learning;tracking},
  doi={10.1109/ACDT.2018.8593130}}

@article{https://doi.org/10.1111/j.1467-7687.2008.00682.x,
author = {Richardson, Fiona M. and Thomas, Michael S.C.},
title = {Critical periods and catastrophic interference effects in the development of self-organizing feature maps},
journal = {Developmental Science},
volume = {11},
number = {3},
pages = {371-389},
doi = {https://doi.org/10.1111/j.1467-7687.2008.00682.x},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1467-7687.2008.00682.x},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1467-7687.2008.00682.x},
abstract = {Abstract The use of self-organizing feature maps (SOFM) in models of cognitive development has frequently been associated with explanations of critical or sensitive periods. By contrast, error-driven connectionist models of development have been linked with catastrophic interference between new knowledge and old knowledge. We introduce a set of simulations that systematically evaluate the conditions under which SOFMs demonstrate critical/sensitive periods in development versus those under which they display interference effects. We explored the relative contribution of network parameters (for example, whether learning rate and neighbourhood reduce across training), the representational resources available to the network, and the similarity between old and new knowledge in determining the functional plasticity of the maps. The SOFMs that achieved the best discrimination and topographic organization also exhibited sensitive periods in development while showing lower plasticity and hence limited interference. However, fast developing, coarser SOFMs also produced topologically organized representations, while permanently retaining their plasticity. We argue that the impact of map organization on behaviour must be interpreted in terms of the cognitive processes that the map is driving.},
year = {2008}
}

@article{ding2022rgb,
  author    = {Ding, Ing-Jr and Zheng, Nai-Wei},
  title     = {RGB-D Depth-Sensor-Based Hand Gesture Recognition Using Deep Learning of Depth Images with Shadow Effect Removal for Smart Gesture Communication},
  journal   = {Sensors and Materials},
  volume    = {34},
  number    = {1},
  pages     = {203-},
  year      = {2022},
}

@misc{fal,
    title = {Research and Knowledge Exchange Integrity and Ethics},
    author = {Falmouth University},
    year = {2022},
    note = {Last accessed March 4th 2024}
}


@misc{yolo:github,
    title = {Ultralytics YOLOv8},
    author = {johnnynunez and glenn-jocher},
    note = {Last accessed Februrary 29th 2024},
    url = {https://github.com/ultralytics/ultralytics},
}

@misc{
rock-paper-scissors-detection_dataset,
title = { Rock Paper Scissors Dataset },
type = { Open Source Dataset },
author = { Team Roboflow },
howpublished = { \url{ https://universe.roboflow.com/team-roboflow/rock-paper-scissors-detection } },
url = { https://universe.roboflow.com/team-roboflow/rock-paper-scissors-detection },
journal = { Roboflow Universe },
publisher = { Roboflow },
year = { 2023 },
month = { jan },
note = { visited on 2024-03-08 },
}

@INPROCEEDINGS{algorithmic:racism,
  author={De Souza Santos, Ronnie and De Lima, Luiz Fernando and Magalhães, Cleyton},
  booktitle={2023 ACM/IEEE International Symposium on Empirical Software Engineering and Measurement (ESEM)}, 
  title={The Perspective of Software Professionals on Algorithmic Racism}, 
  year={2023},
  volume={},
  number={},
  pages={1-10},
  keywords={Surveys;Training;Industries;Machine learning algorithms;Software algorithms;Diversity reception;Machine learning;EDI;racism;software development},
  doi={10.1109/ESEM56168.2023.10304856}}
